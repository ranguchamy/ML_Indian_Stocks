{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d1c42-c82c-41d4-af09-3f0483261d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automated Daily Deal with Special Client and without email client and without file movement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066d991-b320-4d0e-b891-4c7a6d18fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip050120242024.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Inbound'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Outbound'\n",
    "\n",
    "# Read values to match from the Excel file\n",
    "values_df = pd.read_excel(values_excel_path)\n",
    "\n",
    "# Extract the values from the relevant column (e.g., 'Scrip Code')\n",
    "values_to_match = values_df['Scrip Code'].astype(str).str.lower().tolist()\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Your send_email function\n",
    "def send_email(subject, body):\n",
    "    # Configure email settings\n",
    "    sender_email = \"healthyplusrich@gmail.com\"\n",
    "    receiver_email = \"akirabots@gmail.com\"\n",
    "    password = \"password\"\n",
    "\n",
    "    # Create email message\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "\n",
    "    # Send email\n",
    "    try:\n",
    "        # Send email\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "            print(\"Email sent successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")\n",
    "\n",
    "def display_top_transactions_charts(unique_action_row, max_charts=5):\n",
    "    # Calculate the total number of charts\n",
    "    total_charts = int(np.ceil(len(unique_action_row) / rows_per_chart))\n",
    "\n",
    "    # Iterate through the data and display a maximum of three charts for each set of 25 rows\n",
    "    for chart_num in range(min(total_charts, max_charts)):\n",
    "        start_index = chart_num * rows_per_chart\n",
    "        end_index = (chart_num + 1) * rows_per_chart\n",
    "        subset_data = unique_action_row.iloc[start_index:end_index]\n",
    "\n",
    "        # Create a bar chart with unique patterns for bars with the same code\n",
    "        plt.figure(figsize=(24, 12))\n",
    "        \n",
    "        # Adjust the width and spacing between bars\n",
    "        width = 0.6\n",
    "        spacing = 0.2\n",
    "\n",
    "        # Define colors based on action\n",
    "        mild_green = '#b3ffb3'  # Mild green color\n",
    "        mild_red = '#ffb3b3'    # Mild red color\n",
    "        mild_orange = '#ffcc99'  # Mild orange color\n",
    "        mild_yellow = '#ffffb3'  # Mild yellow color\n",
    "\n",
    "        colors = [\n",
    "            mild_green if (isinstance(action, str) and action.lower() in ['acquisition', 'purchase']) else\n",
    "            mild_red if (isinstance(action, str) and action.lower() in ['sell', 'disposal']) else\n",
    "            mild_orange if (isinstance(action, str) and action.lower() == 'revoke') else\n",
    "            mild_yellow for action in subset_data['Action']\n",
    "        ]\n",
    "\n",
    "        bars = plt.bar(np.arange(len(subset_data)) * (width + spacing), subset_data['Amount'], width=width, color=colors, edgecolor='black')\n",
    "\n",
    "        # Display the 'Code' and 'Client Name' on the x-axis\n",
    "        x_labels = [\n",
    "            f\"{code}\\n{name}\\n{datetime.strptime(file_date, '%Y%m%d').strftime('%d/%m/%y')}\" \n",
    "            for code, name, file_date in zip(subset_data['Code'], subset_data['Client Name'], subset_data['File Date'])\n",
    "        ]\n",
    "        \n",
    "        # Center the labels between bars\n",
    "        plt.xticks(np.arange(len(subset_data)) * (width + spacing) + width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "        # Display the formatted amount, action, and file date on top of each bar\n",
    "        for bar, amount, action, file_date in zip(bars, subset_data['Amount'], subset_data['Action'], subset_data['File Date']):\n",
    "            formatted_amount = f'{amount / 1_000:.2f}K' if amount < 1_000_000 else f'{amount / 1_000_000:.2f}M'\n",
    "            formatted_file_date = datetime.strptime(file_date, '%Y%m%d').strftime('%d/%m/%y')\n",
    "\n",
    "            # Adjust the position calculation to ensure finite values\n",
    "            position = min(bar.get_height() + 0.005 * max(subset_data['Amount']), max(subset_data['Amount']))\n",
    "\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, position,\n",
    "                     f'{formatted_amount}\\n{action}\\n{formatted_file_date}', ha='center', va='bottom')\n",
    "\n",
    "        # Add unique patterns for bars with the same code\n",
    "        unique_codes = subset_data['Code'].unique()\n",
    "        for code, bar in zip(unique_codes, bars):\n",
    "            indices = np.where(subset_data['Code'] == code)[0]\n",
    "            if len(indices) > 1:\n",
    "                for i, index in enumerate(indices):\n",
    "                    bar.set_hatch('/')\n",
    "                    if i % 2 == 1:\n",
    "                        bar.set_hatch('\\\\')\n",
    "\n",
    "        # Show the chart\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# def display_top_transactions_charts(unique_action_row, max_charts=3):\n",
    "#     # Calculate the total number of charts\n",
    "#     total_charts = int(np.ceil(len(unique_action_row) / rows_per_chart))\n",
    "\n",
    "#     # Iterate through the data and display a maximum of three charts for each set of 25 rows\n",
    "#     for chart_num in range(min(total_charts, max_charts)):\n",
    "#         start_index = chart_num * rows_per_chart\n",
    "#         end_index = (chart_num + 1) * rows_per_chart\n",
    "#         subset_data = unique_action_row.iloc[start_index:end_index]\n",
    "\n",
    "#         # Create a bar chart with unique patterns for bars with the same code\n",
    "#         plt.figure(figsize=(24, 12))\n",
    "        \n",
    "#         # Adjust the width and spacing between bars\n",
    "#         width = 0.6\n",
    "#         spacing = 0.2\n",
    "\n",
    "#         # Define colors based on action\n",
    "#         mild_green = '#b3ffb3'  # Mild green color\n",
    "#         mild_red = '#ffb3b3'    # Mild red color\n",
    "#         colors = [mild_green if (isinstance(action, str) and action.lower() in ['acquisition', 'purchase']) else mild_red for action in subset_data['Action']]\n",
    "\n",
    "#         bars = plt.bar(np.arange(len(subset_data)) * (width + spacing), subset_data['Amount'], width=width, color=colors, edgecolor='black')\n",
    "\n",
    "#         # Add labels and title\n",
    "#         plt.xlabel('Transaction Index')\n",
    "#         plt.ylabel('Amount')\n",
    "#         plt.title(f'Top Transactions (Rows {start_index + 1} to {end_index})')\n",
    "\n",
    "#         # Display the 'Code' and 'Client Name' on the x-axis\n",
    "#         x_labels = [f\"{code}\\n{name}\" for code, name in zip(subset_data['Code'], subset_data['Client Name'])]\n",
    "        \n",
    "#         # Center the labels between bars\n",
    "#         plt.xticks(np.arange(len(subset_data)) * (width + spacing) + width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "#         # Display the formatted amount and action on top of each bar\n",
    "#         for bar, amount, action in zip(bars, subset_data['Amount'], subset_data['Action']):\n",
    "#             formatted_amount = f'{amount / 1_000:.2f}K' if amount < 1_000_000 else f'{amount / 1_000_000:.2f}M'\n",
    "#             action_str = str(action) if isinstance(action, str) else ''\n",
    "            \n",
    "#             # Check if the position values are finite\n",
    "#             if np.isfinite(bar.get_x()) and np.isfinite(bar.get_height()):\n",
    "#                 plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05 * max(subset_data['Amount']), f'{formatted_amount}\\n{action_str}', ha='center', va='bottom')\n",
    "\n",
    "#         # Add unique patterns for bars with the same code\n",
    "#         unique_codes = subset_data['Code'].unique()\n",
    "#         for code, bar in zip(unique_codes, bars):\n",
    "#             indices = np.where(subset_data['Code'] == code)[0]\n",
    "#             if len(indices) > 1:\n",
    "#                 for i, index in enumerate(indices):\n",
    "#                     bar.set_hatch('/')\n",
    "#                     if i % 2 == 1:\n",
    "#                         bar.set_hatch('\\\\')\n",
    "\n",
    "#         # Show the chart\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "# def display_top_transactions_charts(unique_action_row, max_charts=3):\n",
    "#     # Calculate the total number of charts\n",
    "#     total_charts = int(np.ceil(len(unique_action_row) / rows_per_chart))\n",
    "\n",
    "#     # Iterate through the data and display a maximum of three charts for each set of 25 rows\n",
    "#     for chart_num in range(min(total_charts, max_charts)):\n",
    "#         start_index = chart_num * rows_per_chart\n",
    "#         end_index = (chart_num + 1) * rows_per_chart\n",
    "#         subset_data = unique_action_row.iloc[start_index:end_index]\n",
    "\n",
    "#         # Create a bar chart with unique patterns for bars with the same code\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "        \n",
    "#         # Adjust the width and spacing between bars\n",
    "#         width = 0.6\n",
    "#         spacing = 0.2\n",
    "#         bars = plt.bar(np.arange(len(subset_data)) * (width + spacing), subset_data['Amount'], width=width, color='skyblue', edgecolor='black')\n",
    "\n",
    "#         # Add labels and title\n",
    "#         plt.xlabel('Transaction Index')\n",
    "#         plt.ylabel('Amount')\n",
    "#         plt.title(f'Top Transactions (Rows {start_index + 1} to {end_index})')\n",
    "\n",
    "#         # Display the 'Code' and 'Client Name' on the x-axis\n",
    "#         x_labels = [f\"{code}\\n{name}\" for code, name in zip(subset_data['Code'], subset_data['Client Name'])]\n",
    "        \n",
    "#         # Center the labels between bars\n",
    "#         plt.xticks(np.arange(len(subset_data)) * (width + spacing) + width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "#         # Display the formatted amount on top of each bar\n",
    "#         for bar, amount in zip(bars, subset_data['Amount']):\n",
    "#             formatted_amount = f'{amount / 1_000:.2f}K' if amount < 1_000_000 else f'{amount / 1_000_000:.2f}M'\n",
    "#             plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05 * max(subset_data['Amount']), formatted_amount, ha='center', va='bottom')\n",
    "\n",
    "#         # Add unique patterns for bars with the same code\n",
    "#         unique_codes = subset_data['Code'].unique()\n",
    "#         for code, bar in zip(unique_codes, bars):\n",
    "#             indices = np.where(subset_data['Code'] == code)[0]\n",
    "#             if len(indices) > 1:\n",
    "#                 for i, index in enumerate(indices):\n",
    "#                     bar.set_hatch('/')\n",
    "#                     if i % 2 == 1:\n",
    "#                         bar.set_hatch('\\\\')\n",
    "\n",
    "#         # Show the chart\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "def process_data(process_df, price_col='Average Price', quantity_col='Quantity'):\n",
    "    # Calculate 'Amount' column\n",
    "\n",
    "    process_df = process_df.copy()\n",
    "    process_df['Amount'] = process_df[price_col] * process_df[quantity_col]\n",
    "\n",
    "    # Get unique action rows\n",
    "    unique_action_rows = process_df.groupby(['File Date', 'Code', 'Client Name']).filter(lambda x: x['Action'].nunique() == 1)\n",
    "    print(\"Only Buy or Sell:\")\n",
    "    # print(tabulate(unique_action_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    #Display Chart\n",
    "    display_top_transactions_charts(unique_action_rows)\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Dictionary to store results for each sheet name\n",
    "    merged_results = {}\n",
    "\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Convert the fourth column to lowercase and filter rows\n",
    "            filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().isin(map(str.lower, values_to_match))]\n",
    "\n",
    "            # Drop the specified columns\n",
    "            filtered_rows = filtered_rows.drop(columns=['Stock URL', 'ISIN', 'Stock Deals Page'])\n",
    "\n",
    "            # Add a new column for file date\n",
    "            filtered_rows['File Date'] = file_date\n",
    "\n",
    "            # Check if the sheet name exists in the merged results dictionary\n",
    "            if sheet_name not in merged_results:\n",
    "                merged_results[sheet_name] = filtered_rows\n",
    "            else:\n",
    "                # Append the filtered rows to the existing sheet name\n",
    "                merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "            \n",
    "\n",
    "\n",
    "    # Display merged results\n",
    "    for sheet_name, merged_df in merged_results.items():\n",
    "        # Display the sheet name\n",
    "        print(f\"\\nSheet Name: {sheet_name}\")\n",
    "    \n",
    "        # Check if there are any rows in the merged result\n",
    "        if not merged_df.empty:\n",
    "            # Sort the result based on 'Code' and 'File Date'\n",
    "            #sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "            sorted_rows = merged_df.sort_values(by=['File Date', 'Code'], ascending=[False, True])\n",
    "\n",
    "            # Display the sorted rows in a tabular format\n",
    "            # print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "            # Calculate the new column by multiplying \"Average Price\" and \"Quantity\" for 'Bulk Block Deals'\n",
    "            if sheet_name == 'Bulk Block Deals':\n",
    "                   process_data(sorted_rows, price_col='Average Price', quantity_col='Quantity')\n",
    "            if sheet_name == 'Insider Disclosures':\n",
    "                   process_data(sorted_rows, price_col='Avg. Price', quantity_col='Quantity')\n",
    "            if sheet_name == 'SAST-Significant Acquisitions':\n",
    "                   process_data(sorted_rows, price_col='Last Traded Price', quantity_col='Quantity')\n",
    "\n",
    "\n",
    "\n",
    "            # Read the second sheet named 'Client' from Scrip.xlsx\n",
    "            client_sheet_df = pd.read_excel(values_excel_path, sheet_name='Client', header=None, skiprows=1)\n",
    "            clients_info = client_sheet_df.iloc[:, :2].rename(columns={0: 'Client Code', 1: 'Client Name'})\n",
    "            clients_info['Client Code'] = clients_info['Client Code'].astype(str).str.lower()\n",
    "    \n",
    "            # Filter rows in sorted_rows where 'Client Name' partially matches 'Client Code' list\n",
    "            special_clients = sorted_rows[sorted_rows['Client Name'].astype(str).str.lower().str.contains('|'.join(clients_info['Client Code'].tolist()), na=False)]\n",
    "    \n",
    "            # Send email with the result\n",
    "            email_subject = f\"Results for {sheet_name}\"\n",
    "            email_body = tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False)\n",
    "            #send_email(email_subject, email_body)\n",
    "    \n",
    "            # # Move the file to the outbound folder after processing all sheets\n",
    "            # outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "            # os.rename(file_path, outbound_file_path)\n",
    "            # print(f\"File moved to: {outbound_file_path}\")\n",
    "            \n",
    "            # Display special clients in a separate tabular format\n",
    "            if not special_clients.empty:\n",
    "                print(\"\\nSpecial Clients:\")\n",
    "                # print(tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "                # Calculate the new column by multiplying \"Average Price\" and \"Quantity\" for 'Bulk Block Deals'\n",
    "                if sheet_name == 'Bulk Block Deals':\n",
    "                       process_data(special_clients, price_col='Average Price', quantity_col='Quantity')\n",
    "                if sheet_name == 'Insider Disclosures':\n",
    "                       process_data(special_clients, price_col='Avg. Price', quantity_col='Quantity')\n",
    "                if sheet_name == 'SAST-Significant Acquisitions':\n",
    "                       process_data(special_clients, price_col='Last Traded Price', quantity_col='Quantity')\n",
    "\n",
    "                \n",
    "                email_subject = f\"Results for Special Client {sheet_name}\"\n",
    "                email_body = tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False)\n",
    "                #send_email(email_subject, email_body)\n",
    "                \n",
    "            else:\n",
    "                print(\"No special clients present.\")\n",
    "        else:\n",
    "            print(\"No data present.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91c83f-86ca-4885-bb80-d9e175b879a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automated Daily Deal with Special Client without email client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ea096-6cb1-48c1-9ef8-0136d703597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Your send_email function\n",
    "def send_email(subject, body):\n",
    "    # Configure email settings\n",
    "    sender_email = \"healthyplusrich@gmail.com\"\n",
    "    receiver_email = \"akirabots@gmail.com\"\n",
    "    password = \"password\"\n",
    "\n",
    "    # Create email message\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "\n",
    "    # Send email\n",
    "    try:\n",
    "        # Send email\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "            print(\"Email sent successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")\n",
    "\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip050120242024.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Inbound'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Outbound'\n",
    "\n",
    "# Read values to match from the Excel file\n",
    "values_df = pd.read_excel(values_excel_path)\n",
    "\n",
    "# Extract the values from the relevant column (e.g., 'Scrip Code')\n",
    "values_to_match = values_df['Scrip Code'].astype(str).str.lower().tolist()\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Dictionary to store results for each sheet name\n",
    "    merged_results = {}\n",
    "\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Convert the fourth column to lowercase and filter rows\n",
    "            filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().isin(map(str.lower, values_to_match))]\n",
    "\n",
    "            # Drop the specified columns\n",
    "            filtered_rows = filtered_rows.drop(columns=['Stock URL', 'ISIN', 'Stock Deals Page'])\n",
    "\n",
    "            # Add a new column for file date\n",
    "            filtered_rows['File Date'] = file_date\n",
    "\n",
    "            # Check if the sheet name exists in the merged results dictionary\n",
    "            if sheet_name not in merged_results:\n",
    "                merged_results[sheet_name] = filtered_rows\n",
    "            else:\n",
    "                # Append the filtered rows to the existing sheet name\n",
    "                merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "        # try:\n",
    "        #     if os.path.exists(file_path):\n",
    "        #         outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "                \n",
    "        #         # Attempt to move the file\n",
    "        #         os.rename(file_path, outbound_file_path)\n",
    "        #         print(f\"File moved to: {outbound_file_path}\")\n",
    "        #     else:\n",
    "        #         print(f\"Error: File not found at: {file_path}\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error occurred while moving the file: {e}\")\n",
    "          \n",
    "\n",
    "    # Display merged results\n",
    "    for sheet_name, merged_df in merged_results.items():\n",
    "        # Display the sheet name\n",
    "        print(f\"\\nSheet Name: {sheet_name}\")\n",
    "    \n",
    "        # Check if there are any rows in the merged result\n",
    "        if not merged_df.empty:\n",
    "            # Sort the result based on 'Code' and 'File Date'\n",
    "\n",
    "            sorted_rows = merged_df.sort_values(by=['File Date', 'Code'], ascending=[False, True])\n",
    "            \n",
    "    \n",
    "            # Display the sorted rows in a tabular format\n",
    "            print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "            \n",
    "\n",
    "    \n",
    "            # Read the second sheet named 'Client' from Scrip.xlsx\n",
    "            client_sheet_df = pd.read_excel(values_excel_path, sheet_name='Client', header=None, skiprows=1)\n",
    "            clients_info = client_sheet_df.iloc[:, :2].rename(columns={0: 'Client Code', 1: 'Client Name'})\n",
    "            clients_info['Client Code'] = clients_info['Client Code'].astype(str).str.lower()\n",
    "    \n",
    "            # Filter rows in sorted_rows where 'Client Name' partially matches 'Client Code' list\n",
    "            special_clients = sorted_rows[sorted_rows['Client Name'].astype(str).str.lower().str.contains('|'.join(clients_info['Client Code'].tolist()), na=False)]\n",
    "    \n",
    "            # Send email with the result\n",
    "            email_subject = f\"Results for {sheet_name}\"\n",
    "            email_body = tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False)\n",
    "            #send_email(email_subject, email_body)\n",
    "\n",
    "            \n",
    "            # Display special clients in a separate tabular format\n",
    "            if not special_clients.empty:\n",
    "                print(\"\\nSpecial Clients:\")\n",
    "                print(tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    \n",
    "                email_subject = f\"Results for Special Client {sheet_name}\"\n",
    "                email_body = tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False)\n",
    "                #send_email(email_subject, email_body)\n",
    "                \n",
    "            else:\n",
    "                print(\"No special clients present.\")\n",
    "        else:\n",
    "            print(\"No data present.\")\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e6905-292b-4d67-b89e-6f32931a2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automated Daily Deal with email client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d3f27-801c-4326-a352-b11db5e0d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Your send_email function\n",
    "def send_email(subject, body):\n",
    "    # Configure email settings\n",
    "    sender_email = \"healthyplusrich@gmail.com\"\n",
    "    receiver_email = \"akirabots@gmail.com\"\n",
    "    password = \"password\"\n",
    "\n",
    "    # Create email message\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "\n",
    "    # Send email\n",
    "    try:\n",
    "        # Send email\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "            print(\"Email sent successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip05012024.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Inbound'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Outbound'\n",
    "\n",
    "# Read values to match from the Excel file\n",
    "values_df = pd.read_excel(values_excel_path)\n",
    "\n",
    "# Extract the values from the relevant column (e.g., 'Scrip Code')\n",
    "values_to_match = values_df['Scrip Code'].astype(str).str.lower().tolist()\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Dictionary to store results for each sheet name\n",
    "    merged_results = {}\n",
    "\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Convert the fourth column to lowercase and filter rows\n",
    "            filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().isin(map(str.lower, values_to_match))]\n",
    "\n",
    "            # Drop the specified columns\n",
    "            filtered_rows = filtered_rows.drop(columns=['Stock URL', 'ISIN', 'Stock Deals Page'])\n",
    "\n",
    "            # Add a new column for file date\n",
    "            filtered_rows['File Date'] = file_date\n",
    "\n",
    "            # Check if the sheet name exists in the merged results dictionary\n",
    "            if sheet_name not in merged_results:\n",
    "                merged_results[sheet_name] = filtered_rows\n",
    "            else:\n",
    "                # Append the filtered rows to the existing sheet name\n",
    "                merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "        outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "        os.rename(file_path, outbound_file_path)\n",
    "        print(f\"File moved to: {outbound_file_path}\")\n",
    "\n",
    "    # Check if there are any results\n",
    "    if any(merged_results):\n",
    "        # Display merged results\n",
    "        for sheet_name, merged_df in merged_results.items():\n",
    "            # Display the sheet name\n",
    "            print(f\"\\nSheet Name: {sheet_name}\")\n",
    "\n",
    "            # Check if there are any rows in the merged result\n",
    "            if not merged_df.empty:\n",
    "                # Sort the result based on 'Code' and 'File Date'\n",
    "                #sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "                sorted_rows = merged_df.sort_values(by=['File Date', 'Code'], ascending=[False, True])\n",
    "    \n",
    "                # Display the sorted rows in a tabular format\n",
    "                print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "                # Send email with the result\n",
    "                email_subject = f\"Results for {sheet_name}\"\n",
    "                email_body = tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False)\n",
    "                send_email(email_subject, email_body)\n",
    "            else:\n",
    "                print(\"No data present.\")\n",
    "    else:\n",
    "        print(\"No results found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d705f-2f16-4c9c-aa2d-eefa92126151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
