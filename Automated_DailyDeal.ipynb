{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d1c42-c82c-41d4-af09-3f0483261d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automated Daily Deal with Special Client and without email client and without file movement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066d991-b320-4d0e-b891-4c7a6d18fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip180120241900.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Inbound'\n",
    "# outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Outbound'\n",
    "\n",
    "# Read values to match from the Excel file\n",
    "values_df = pd.read_excel(values_excel_path)\n",
    "\n",
    "# Extract the values from the relevant column (e.g., 'Scrip Code')\n",
    "# values_to_match = values_df['Next 1000'].astype(str).str.lower().tolist()\n",
    "values_to_match = values_df['Scrip Code'].astype(str).str.lower().tolist()\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Your send_email function\n",
    "def send_email(subject, body):\n",
    "    # Configure email settings\n",
    "    sender_email = \"healthyplusrich@gmail.com\"\n",
    "    receiver_email = \"akirabots@gmail.com\"\n",
    "    password = \"password\"\n",
    "\n",
    "    # Create email message\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "\n",
    "    # Send email\n",
    "    try:\n",
    "        # Send email\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "            print(\"Email sent successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")\n",
    "\n",
    "def display_top_transactions_charts(unique_action_row, max_charts=10):\n",
    "    # Calculate the total number of charts\n",
    "    rows_per_chart = 25  # You can adjust the value based on your requirements\n",
    "\n",
    "    total_charts = int(np.ceil(len(unique_action_row) / rows_per_chart))\n",
    "\n",
    "    # Iterate through the data and display a maximum of three charts for each set of 25 rows\n",
    "    for chart_num in range(min(total_charts, max_charts)):\n",
    "        start_index = chart_num * rows_per_chart\n",
    "        end_index = (chart_num + 1) * rows_per_chart\n",
    "        subset_data = unique_action_row.iloc[start_index:end_index]\n",
    "\n",
    "        # Create a bar chart with unique patterns for bars with the same code\n",
    "        plt.figure(figsize=(24, 12))\n",
    "        \n",
    "        # Adjust the width and spacing between bars\n",
    "        width = 0.6\n",
    "        spacing = 0.2\n",
    "\n",
    "        # Define colors based on action\n",
    "        mild_green = '#b3ffb3'  # Mild green color\n",
    "        mild_red = '#ffb3b3'    # Mild red color\n",
    "        mild_orange = '#ffcc99'  # Mild orange color\n",
    "        mild_yellow = '#ffffb3'  # Mild yellow color\n",
    "\n",
    "        colors = [\n",
    "            mild_green if (isinstance(action, str) and action.lower() in ['acquisition', 'purchase']) else\n",
    "            mild_red if (isinstance(action, str) and action.lower() in ['sell', 'disposal']) else\n",
    "            mild_orange if (isinstance(action, str) and action.lower() == 'revoke') else\n",
    "            mild_yellow for action in subset_data['Action']\n",
    "        ]\n",
    "\n",
    "        bars = plt.bar(np.arange(len(subset_data)) * (width + spacing), subset_data['Amount'], width=width, color=colors, edgecolor='black')\n",
    "\n",
    "        # Display the 'Code' and 'Client Name' on the x-axis\n",
    "        x_labels = [\n",
    "            f\"{code}\\n{stock}\\n{name}\" \n",
    "            for code, stock, name,  in zip(subset_data['Code'],subset_data['Stock'], subset_data['Client Name'])\n",
    "        ]\n",
    "        \n",
    "        # Center the labels between bars\n",
    "        plt.xticks(np.arange(len(subset_data)) * (width + spacing) + width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "        # Display the formatted amount, action, and file date on top of each bar\n",
    "        for bar, amount, action, file_date in zip(bars, subset_data['Amount'], subset_data['Action'], subset_data['File Date']):\n",
    "            formatted_amount = f'{amount / 1_000:.2f}K' if amount < 1_000_000 else f'{amount / 1_000_000:.2f}M'\n",
    "            formatted_file_date = datetime.strptime(file_date, '%Y%m%d').strftime('%d/%m/%y')\n",
    "            # Adjust the position calculation to ensure finite values\n",
    "            position = min(bar.get_height() + 0.005 * max(subset_data['Amount']), max(subset_data['Amount']))\n",
    "\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, position,\n",
    "                     f'{formatted_amount}\\n{action}\\n{formatted_file_date}', ha='center', va='bottom')\n",
    "\n",
    "        # Add unique patterns for bars with the same code\n",
    "        unique_codes = subset_data['Code'].unique()\n",
    "        for code, bar in zip(unique_codes, bars):\n",
    "            indices = np.where(subset_data['Code'] == code)[0]\n",
    "            if len(indices) > 1:\n",
    "                for i, index in enumerate(indices):\n",
    "                    bar.set_hatch('/')\n",
    "                    if i % 2 == 1:\n",
    "                        bar.set_hatch('\\\\')\n",
    "\n",
    "        # Show the chart\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def process_data(process_df, price_col='Average Price', quantity_col='Quantity'):\n",
    "    # Calculate 'Amount' column\n",
    "\n",
    "    process_df = process_df.copy()\n",
    "    process_df['Amount'] = process_df[price_col] * process_df[quantity_col]\n",
    "\n",
    "    # Get unique action rows\n",
    "    unique_action_rows = process_df.groupby(['File Date', 'Code', 'Client Name']).filter(lambda x: x['Action'].nunique() == 1)\n",
    "    print(\"Only Buy or Sell:\")\n",
    "    print(tabulate(unique_action_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    #Display Chart\n",
    "    display_top_transactions_charts(unique_action_rows)\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Dictionary to store results for each sheet name\n",
    "    merged_results = {}\n",
    "\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "        # Iterate through each sheet\n",
    "        # print(\"values_to_match\")\n",
    "        # print(values_to_match)\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Convert the fourth column to lowercase and filter rows\n",
    "            filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().isin(map(str.lower, values_to_match))]\n",
    "\n",
    "            #filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().str.contains('|'.join(map(str.lower, values_to_match)))]\n",
    "            #filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().str.contains(r'\\b(?:' + '|'.join(map(re.escape, map(str.lower, values_to_match))) + r')\\b')]\n",
    "            # print(df.iloc[:, 3].astype(str).str.lower())\n",
    "            # Drop the specified columns\n",
    "            filtered_rows = filtered_rows.drop(columns=['Stock URL', 'ISIN', 'Stock Deals Page'])\n",
    "\n",
    "            # Add a new column for file date\n",
    "            filtered_rows['File Date'] = file_date\n",
    "\n",
    "            # Check if the sheet name exists in the merged results dictionary\n",
    "            if sheet_name not in merged_results:\n",
    "                merged_results[sheet_name] = filtered_rows\n",
    "            else:\n",
    "                # Append the filtered rows to the existing sheet name\n",
    "                merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "            \n",
    "\n",
    "\n",
    "    # Display merged results\n",
    "    for sheet_name, merged_df in merged_results.items():\n",
    "        # Display the sheet name\n",
    "        print(f\"\\nSheet Name: {sheet_name}\")\n",
    "    \n",
    "        # Check if there are any rows in the merged result\n",
    "        if not merged_df.empty:\n",
    "            # Sort the result based on 'Code' and 'File Date'\n",
    "            #sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "            sorted_rows = merged_df.sort_values(by=['File Date', 'Code'], ascending=[False, True])\n",
    "\n",
    "            # # Display the sorted rows in a tabular format\n",
    "            # print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "            # # Calculate the new column by multiplying \"Average Price\" and \"Quantity\" for 'Bulk Block Deals'\n",
    "            # if sheet_name == 'Bulk Block Deals':\n",
    "            #        process_data(sorted_rows, price_col='Average Price', quantity_col='Quantity')\n",
    "            # if sheet_name == 'Insider Disclosures':\n",
    "            #        process_data(sorted_rows, price_col='Avg. Price', quantity_col='Quantity')\n",
    "            # if sheet_name == 'SAST-Significant Acquisitions':\n",
    "            #        process_data(sorted_rows, price_col='Last Traded Price', quantity_col='Quantity')\n",
    "\n",
    "\n",
    "\n",
    "            # Read the second sheet named 'Client' from Scrip.xlsx\n",
    "            client_sheet_df = pd.read_excel(values_excel_path, sheet_name='Client', header=None, skiprows=1)\n",
    "            clients_info = client_sheet_df.iloc[:, :2].rename(columns={0: 'Client Code', 1: 'Client Name'})\n",
    "            clients_info['Client Code'] = clients_info['Client Code'].astype(str).str.lower()\n",
    "    \n",
    "            # Filter rows in sorted_rows where 'Client Name' partially matches 'Client Code' list\n",
    "            special_clients = sorted_rows[sorted_rows['Client Name'].astype(str).str.lower().str.contains('|'.join(clients_info['Client Code'].tolist()), na=False)]\n",
    "    \n",
    "            # Send email with the result\n",
    "            email_subject = f\"Results for {sheet_name}\"\n",
    "            email_body = tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False)\n",
    "            #send_email(email_subject, email_body)\n",
    "    \n",
    "            # # Move the file to the outbound folder after processing all sheets\n",
    "            # outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "            # os.rename(file_path, outbound_file_path)\n",
    "            # print(f\"File moved to: {outbound_file_path}\")\n",
    "            \n",
    "            # Display special clients in a separate tabular format\n",
    "            if not special_clients.empty:\n",
    "                print(\"\\nSpecial Clients:\")\n",
    "                # print(tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "                # Calculate the new column by multiplying \"Average Price\" and \"Quantity\" for 'Bulk Block Deals'\n",
    "                if sheet_name == 'Bulk Block Deals':\n",
    "                       process_data(special_clients, price_col='Average Price', quantity_col='Quantity')\n",
    "                if sheet_name == 'Insider Disclosures':\n",
    "                       process_data(special_clients, price_col='Avg. Price', quantity_col='Quantity')\n",
    "                if sheet_name == 'SAST-Significant Acquisitions':\n",
    "                       process_data(special_clients, price_col='Last Traded Price', quantity_col='Quantity')\n",
    "\n",
    "                \n",
    "                email_subject = f\"Results for Special Client {sheet_name}\"\n",
    "                email_body = tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False)\n",
    "                #send_email(email_subject, email_body)\n",
    "                \n",
    "            else:\n",
    "                print(\"No special clients present.\")\n",
    "        else:\n",
    "            print(\"No data present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca535ccd-1e2c-474e-812c-8ef0276655c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automated Daily Deal with Special Client and Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5354e-de0a-42d4-a808-ee2d434057f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip120120241753.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Inbound'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Outbound'\n",
    "\n",
    "# Read values to match from the Excel file\n",
    "values_df = pd.read_excel(values_excel_path)\n",
    "\n",
    "# Extract the values from the relevant column (e.g., 'Scrip Code')\n",
    "# values_to_match = values_df['Next 1000'].astype(str).str.lower().tolist()\n",
    "values_to_match = values_df['Scrip Code'].astype(str).str.lower().tolist()\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "def get_stock_info(nse_code):\n",
    "    file_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Fundamental\\NSE_Fundamental.xlsx'\n",
    "\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Filter the DataFrame based on the NSE code\n",
    "    filtered_df = df[df['NSE code'] == nse_code]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Select only the required columns\n",
    "    result_df = filtered_df[['Stock Name','Industry Name', 'Current Price Rs', 'Price to Book Value', 'Industry Price to Book TTM','PE TTM Price to Earnings','RSI','Long Term Debt To Equity Annual','ROE Annual %','% Distance from 52week high','EPS Annual Rs','FII holding current Qtr %']]\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "def display_top_transactions_charts(unique_action_row, max_charts=10):\n",
    "    # Calculate the total number of charts\n",
    "    rows_per_chart = 25  # You can adjust the value based on your requirements\n",
    "\n",
    "    total_charts = int(np.ceil(len(unique_action_row) / rows_per_chart))\n",
    "\n",
    "    # Iterate through the data and display a maximum of three charts for each set of 25 rows\n",
    "    for chart_num in range(min(total_charts, max_charts)):\n",
    "        start_index = chart_num * rows_per_chart\n",
    "        end_index = (chart_num + 1) * rows_per_chart\n",
    "        subset_data = unique_action_row.iloc[start_index:end_index]\n",
    "\n",
    "        # Create a bar chart with unique patterns for bars with the same code\n",
    "        plt.figure(figsize=(24, 12))\n",
    "        \n",
    "        # Adjust the width and spacing between bars\n",
    "        width = 0.6\n",
    "        spacing = 0.2\n",
    "\n",
    "        # Define colors based on action\n",
    "        mild_green = '#b3ffb3'  # Mild green color\n",
    "        mild_red = '#ffb3b3'    # Mild red color\n",
    "        mild_orange = '#ffcc99'  # Mild orange color\n",
    "        mild_yellow = '#ffffb3'  # Mild yellow color\n",
    "\n",
    "        colors = [\n",
    "            mild_green if (isinstance(action, str) and action.lower() in ['acquisition', 'purchase']) else\n",
    "            mild_red if (isinstance(action, str) and action.lower() in ['sell', 'disposal']) else\n",
    "            mild_orange if (isinstance(action, str) and action.lower() == 'revoke') else\n",
    "            mild_yellow for action in subset_data['Action']\n",
    "        ]\n",
    "\n",
    "        bars = plt.bar(np.arange(len(subset_data)) * (width + spacing), subset_data['Amount'], width=width, color=colors, edgecolor='black')\n",
    "\n",
    "        # Display the 'Code' and 'Client Name' on the x-axis\n",
    "        x_labels = [\n",
    "            f\"{code}\\n{stock}\\n{name}\" \n",
    "            for code, stock, name,  in zip(subset_data['Code'],subset_data['Stock'], subset_data['Client Name'])\n",
    "        ]\n",
    "        \n",
    "        # Center the labels between bars\n",
    "        plt.xticks(np.arange(len(subset_data)) * (width + spacing) + width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "        # Display the formatted amount, action, and file date on top of each bar\n",
    "        for bar, amount, action, file_date in zip(bars, subset_data['Amount'], subset_data['Action'], subset_data['File Date']):\n",
    "            formatted_amount = f'{amount / 1_000:.2f}K' if amount < 1_000_000 else f'{amount / 1_000_000:.2f}M'\n",
    "            formatted_file_date = datetime.strptime(file_date, '%Y%m%d').strftime('%d/%m/%y')\n",
    "            # Adjust the position calculation to ensure finite values\n",
    "            position = min(bar.get_height() + 0.005 * max(subset_data['Amount']), max(subset_data['Amount']))\n",
    "\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, position,\n",
    "                     f'{formatted_amount}\\n{action}\\n{formatted_file_date}', ha='center', va='bottom')\n",
    "\n",
    "        # Add unique patterns for bars with the same code\n",
    "        unique_codes = subset_data['Code'].unique()\n",
    "        for code, bar in zip(unique_codes, bars):\n",
    "            indices = np.where(subset_data['Code'] == code)[0]\n",
    "            if len(indices) > 1:\n",
    "                for i, index in enumerate(indices):\n",
    "                    bar.set_hatch('/')\n",
    "                    if i % 2 == 1:\n",
    "                        bar.set_hatch('\\\\')\n",
    "\n",
    "        # Show the chart\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "def process_data(process_df, price_col='Average Price', quantity_col='Quantity'):\n",
    "    # Calculate 'Amount' column\n",
    "    process_df = process_df.copy()\n",
    "    process_df['Amount'] = process_df[price_col] * process_df[quantity_col]\n",
    "\n",
    "    # Get unique action rows\n",
    "    unique_action_rows = process_df.groupby(['File Date', 'Code', 'Client Name']).filter(lambda x: x['Action'].nunique() == 1)\n",
    "    print(\"Only Buy or Sell:\")\n",
    "    # print(tabulate(unique_action_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "    # # Collecting Fundamental data for unique buy or sell\n",
    "    # collected_data = pd.DataFrame()\n",
    "\n",
    "    # # Iterate through each unique code and append stock info to collected_data\n",
    "    # for code in unique_action_rows['Code'].unique():\n",
    "    #     stock_info = get_stock_info(code)\n",
    "    #     collected_data = pd.concat([collected_data, stock_info], ignore_index=True)\n",
    "\n",
    "    # # Display the collected DataFrame\n",
    " \n",
    "    # print(tabulate(collected_data, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "    # Display Chart\n",
    "    display_top_transactions_charts(unique_action_rows)\n",
    "\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Dictionary to store results for each sheet name\n",
    "    merged_results = {}\n",
    "\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "        # Iterate through each sheet\n",
    "        # print(\"values_to_match\")\n",
    "        # print(values_to_match)\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Convert the fourth column to lowercase and filter rows\n",
    "            filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().isin(map(str.lower, values_to_match))]\n",
    "\n",
    "            #filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().str.contains('|'.join(map(str.lower, values_to_match)))]\n",
    "            #filtered_rows = df[df.iloc[:, 3].astype(str).str.lower().str.contains(r'\\b(?:' + '|'.join(map(re.escape, map(str.lower, values_to_match))) + r')\\b')]\n",
    "            # print(df.iloc[:, 3].astype(str).str.lower())\n",
    "            # Drop the specified columns\n",
    "            filtered_rows = filtered_rows.drop(columns=['Stock URL', 'ISIN', 'Stock Deals Page'])\n",
    "\n",
    "            # Add a new column for file date\n",
    "            filtered_rows['File Date'] = file_date\n",
    "\n",
    "            # Check if the sheet name exists in the merged results dictionary\n",
    "            if sheet_name not in merged_results:\n",
    "                merged_results[sheet_name] = filtered_rows\n",
    "            else:\n",
    "                # Append the filtered rows to the existing sheet name\n",
    "                merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "            \n",
    "\n",
    "\n",
    "    # Display merged results\n",
    "    for sheet_name, merged_df in merged_results.items():\n",
    "        # Display the sheet name\n",
    "        print(f\"\\nSheet Name: {sheet_name}\")\n",
    "    \n",
    "        # Check if there are any rows in the merged result\n",
    "        if not merged_df.empty:\n",
    "            # Sort the result based on 'Code' and 'File Date'\n",
    "            #sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "            sorted_rows = merged_df.sort_values(by=['File Date', 'Code'], ascending=[False, True])\n",
    "\n",
    "            # Display the sorted rows in a tabular format\n",
    "            # print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "            \n",
    "            # get_stock_info(nse_code)\n",
    "            \n",
    "            # # Calculate the new column by multiplying \"Average Price\" and \"Quantity\" for 'Bulk Block Deals'\n",
    "            # if sheet_name == 'Bulk Block Deals':\n",
    "            #        process_data(sorted_rows, price_col='Average Price', quantity_col='Quantity')\n",
    "            # if sheet_name == 'Insider Disclosures':\n",
    "            #        process_data(sorted_rows, price_col='Avg. Price', quantity_col='Quantity')\n",
    "            # if sheet_name == 'SAST-Significant Acquisitions':\n",
    "            #        process_data(sorted_rows, price_col='Last Traded Price', quantity_col='Quantity')\n",
    "\n",
    "\n",
    "\n",
    "            # Read the second sheet named 'Client' from Scrip.xlsx\n",
    "            client_sheet_df = pd.read_excel(values_excel_path, sheet_name='Client', header=None, skiprows=1)\n",
    "            clients_info = client_sheet_df.iloc[:, :2].rename(columns={0: 'Client Code', 1: 'Client Name'})\n",
    "            clients_info['Client Code'] = clients_info['Client Code'].astype(str).str.lower()\n",
    "    \n",
    "            # Filter rows in sorted_rows where 'Client Name' partially matches 'Client Code' list\n",
    "            special_clients = sorted_rows[sorted_rows['Client Name'].astype(str).str.lower().str.contains('|'.join(clients_info['Client Code'].tolist()), na=False)]\n",
    "    \n",
    "            # Send email with the result\n",
    "            email_subject = f\"Results for {sheet_name}\"\n",
    "            email_body = tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False)\n",
    "            #send_email(email_subject, email_body)\n",
    "    \n",
    "            # # Move the file to the outbound folder after processing all sheets\n",
    "            # outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "            # os.rename(file_path, outbound_file_path)\n",
    "            # print(f\"File moved to: {outbound_file_path}\")\n",
    "            \n",
    "            # Display special clients in a separate tabular format\n",
    "            if not special_clients.empty:\n",
    "                print(\"\\nSpecial Clients:\")\n",
    "                # print(tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "                # Calculate the new column by multiplying \"Average Price\" and \"Quantity\" for 'Bulk Block Deals'\n",
    "                if sheet_name == 'Bulk Block Deals':\n",
    "                       process_data(special_clients, price_col='Average Price', quantity_col='Quantity')\n",
    "                if sheet_name == 'Insider Disclosures':\n",
    "                       process_data(special_clients, price_col='Avg. Price', quantity_col='Quantity')\n",
    "                if sheet_name == 'SAST-Significant Acquisitions':\n",
    "                       process_data(special_clients, price_col='Last Traded Price', quantity_col='Quantity')\n",
    "\n",
    "                \n",
    "                email_subject = f\"Results for Special Client {sheet_name}\"\n",
    "                email_body = tabulate(special_clients, headers='keys', tablefmt='pretty', showindex=False)\n",
    "                #send_email(email_subject, email_body)\n",
    "                \n",
    "            else:\n",
    "                print(\"No special clients present.\")\n",
    "        else:\n",
    "            print(\"No data present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b3ad9-5fd4-4cef-9653-e492a33be9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
