{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d3a3fa4-c7a4-4ed9-b46d-e44d8486a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet Name: Bulk Block Deals\n",
      "+----------------------------------------+------------+------------------------------------------------------------+----------+-----------+----------+---------------------+---------------+----------+----------+-------------------+-----------+\n",
      "|                 Stock                  |    Code    |                        Client Name                         | Exchange | Deal Type |  Action  |        Date         | Average Price | Quantity | Traded % | Last Traded Price | File Date |\n",
      "+----------------------------------------+------------+------------------------------------------------------------+----------+-----------+----------+---------------------+---------------+----------+----------+-------------------+-----------+\n",
      "|            PB Fintech Ltd.             |   543390   |            GOLDMAN SACHS (SINGAPORE) PTE.- ODI             |   BSE    |   Block   | Purchase | 2023-12-15 00:00:00 |    800.05     | 175000.0 |  0.0388  |      789.35       | 20231215  |\n",
      "|    Archean Chemical Industries Ltd.    |    ACI     |     GOLDMAN SACHS FDS GOLDMAN SACHS INDIA EQ PORTFOLIO     |   NSE    |   Bulk    | Purchase | 2023-12-18 00:00:00 |     600.0     | 623609.0 |  0.5054  |       611.5       | 20231218  |\n",
      "| India Shelter Finance Corporation Ltd. | INDIASHLTR | GOLDMAN SACHS FUNDS - GOLDMAN SACHS INDIA EQUITY PORTFOLIO |   NSE    |   Bulk    | Purchase | 2023-12-20 00:00:00 |    593.08     | 591027.0 |  0.5521  |       544.7       | 20231220  |\n",
      "+----------------------------------------+------------+------------------------------------------------------------+----------+-----------+----------+---------------------+---------------+----------+----------+-------------------+-----------+\n",
      "\n",
      "Sheet Name: Insider Trading and SAST\n",
      "No data present.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "\n",
    "# Read values to match from the Excel file (ActiveTrader from third sheet)\n",
    "values_df = pd.read_excel(values_excel_path, sheet_name='Superstars', header=None, skiprows=1)\n",
    "values_to_match = values_df.iloc[:, 0].astype(str).str.lower().tolist()\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Dictionary to store results for each sheet name\n",
    "    merged_results = {}\n",
    "\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None, header=6)  # Headers start from the seventh row\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Convert the 'Client Name' column to lowercase and filter rows\n",
    "            filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
    "\n",
    "            # Check if the columns exist before attempting to drop them\n",
    "            columns_to_drop = ['Stock URL', 'ISIN', 'Stock Deals Page']\n",
    "            columns_to_drop = [col for col in columns_to_drop if col in filtered_rows.columns]\n",
    "            filtered_rows = filtered_rows.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "            # Add a new column for file date\n",
    "            filtered_rows['File Date'] = file_date\n",
    "\n",
    "            # Check if the sheet name exists in the merged results dictionary\n",
    "            if sheet_name not in merged_results:\n",
    "                merged_results[sheet_name] = filtered_rows\n",
    "            else:\n",
    "                # Append the filtered rows to the existing sheet name\n",
    "                merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "        # outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "        # os.rename(file_path, outbound_file_path)\n",
    "        # print(f\"File moved to: {outbound_file_path}\")\n",
    "\n",
    "    # Display merged results\n",
    "    for sheet_name, merged_df in merged_results.items():\n",
    "        # Display the sheet name\n",
    "        print(f\"\\nSheet Name: {sheet_name}\")\n",
    "\n",
    "        # Check if there are any rows in the merged result\n",
    "        if not merged_df.empty:\n",
    "            # Sort the result based on 'Code' and 'File Date'\n",
    "            sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "\n",
    "            # Display the sorted rows in a tabular format\n",
    "            print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "         \n",
    "        else:\n",
    "            print(\"No data present.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca323d5-74ef-48aa-83ab-66c480162587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
