{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606cc58-8402-4145-b823-b14946ea7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bulk Download | Reconciliation of data to Sync with Dail deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb68874-a1cd-4af0-87d7-34a249ac90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MCAP file...\n",
      "\n",
      "Reading Excel file: C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundDataMatch\\20240129-DailyDeals-Trendlyne.xlsx\n",
      "Checking matches for file: 20240129-DailyDeals-Trendlyne.xlsx\n",
      "\n",
      "Combining all DataFrames...\n",
      "\n",
      "Saving DataFrame to: C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundDataMatch\\output\\20240130-DailyDeals-Trendlyne_Bulk.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Path to the folder with Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundDataMatch'\n",
    "\n",
    "# Path to the MCAP31122023.xlsx file\n",
    "mcap_file_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\BSE NSE FindingScripNumber\\MCAP31122023.xlsx'\n",
    "\n",
    "# Read the MCAP file to get the mapping between 'Company Name' and 'Symbol'\n",
    "print(\"Reading MCAP file...\")\n",
    "mcap_df = pd.read_excel(mcap_file_path)\n",
    "\n",
    "mcap_df['Company Name'] = mcap_df['Company Name'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x.lower()) if pd.notnull(x) and \"Bank of\" not in x else x)\n",
    "mcap_df['Company Name'] = mcap_df['Company Name'].str.replace(r'\\s*(ltd|LTD|Ltd)\\.?$', '', regex=True, case=False)\n",
    "\n",
    "# print(mcap_df['Company Name'])\n",
    "company_name_to_symbol = dict(zip(mcap_df['Company Name'], mcap_df['Symbol']))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate through each file in the inbound folder\n",
    "for file_name in os.listdir(inbound_folder_path):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(inbound_folder_path, file_name)\n",
    "        \n",
    "        # Read each Excel file into a DataFrame\n",
    "        print(f\"\\nReading Excel file: {file_path}\")\n",
    "        df = pd.read_excel(file_path, header=1)  # Assuming header starts from the second row\n",
    "        df.rename(columns={'Avg. Price': 'Average Price'}, inplace=True)\n",
    "\n",
    "        df['Stock Name'] = df['Stock'].apply(lambda x: ' '.join(x.split()[:2]) if pd.notnull(x) and \"Bank of\" not in x else x)\n",
    "        df['Stock Name'] = df['Stock Name'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x) if pd.notnull(x) else x).str.lower()\n",
    "\n",
    "\n",
    "        # Check if the 'Stock Name' contains any 'Company Name' in the MCAP file\n",
    "        print(f\"Checking matches for file: {file_name}\")\n",
    "        df['Code'] = df['Stock Name'].apply(lambda stock_name: company_name_to_symbol[max(company_name_to_symbol.keys(), key=lambda company_name: fuzz.ratio(stock_name.lower(), company_name.lower()))] if pd.notnull(stock_name) else None)\n",
    "        \n",
    "        # print(df['Code'] )\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "print(\"\\nCombining all DataFrames...\")\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Define the output path and file name\n",
    "output_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundDataMatch\\output'\n",
    "output_file_name = f\"{pd.Timestamp.now().strftime('%Y%m%d')}-DailyDeals-Trendlyne_Bulk.xlsx\"\n",
    "output_file_path = os.path.join(output_path, output_file_name)\n",
    "\n",
    "# # Save the combined DataFrame to Excel with specific sheet name and column names\n",
    "# print(f\"\\nSaving DataFrame to: {output_file_path}\")\n",
    "# with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
    "#     combined_df.to_excel(writer, index=False, sheet_name='Bulk Block Deals', startrow=1, header=False)\n",
    "#     # Get the xlsxwriter workbook and worksheet objects\n",
    "#     workbook = writer.book\n",
    "#     worksheet = writer.sheets['Bulk Block Deals']\n",
    "    \n",
    "#     # Add the header to the worksheet\n",
    "#     header_format = workbook.add_format({'bold': True, 'text_wrap': True, 'valign': 'top'})\n",
    "#     for col_num, value in enumerate(combined_df.columns.values):\n",
    "#         worksheet.write(0, col_num + 1, value, header_format)\n",
    "\n",
    "#     # Get the dimensions of the DataFrame\n",
    "#     num_rows, num_cols = combined_df.shape\n",
    "    \n",
    "#     # Create a table (DataFrame) object\n",
    "#     worksheet.add_table(0, 0, num_rows, num_cols, {'columns': [{'header': col} for col in combined_df.columns], 'name': 'BulkBlockDealsTable'})\n",
    "\n",
    "#     # Add 'Code' as the 4th column (column D)\n",
    "#     code_column = combined_df['Code']  # Replace 'Code' with the actual column name\n",
    "#     worksheet.write_column(1, 3, code_column)  # Updated index to 3 for column D\n",
    "# Save the combined DataFrame to Excel with specific sheet name and column names\n",
    "print(f\"\\nSaving DataFrame to: {output_file_path}\")\n",
    "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
    "    combined_df.to_excel(writer, index=False, sheet_name='Bulk Block Deals', startrow=1, header=False)\n",
    "    # Get the xlsxwriter workbook and worksheet objects\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Bulk Block Deals']\n",
    "    \n",
    "    # Add the header to the worksheet\n",
    "    header_format = workbook.add_format({'bold': True, 'text_wrap': True, 'valign': 'top'})\n",
    "    for col_num, value in enumerate(combined_df.columns.values):\n",
    "        worksheet.write(0, col_num + 1, value, header_format)\n",
    "\n",
    "    # Get the dimensions of the DataFrame\n",
    "    num_rows, num_cols = combined_df.shape\n",
    "    \n",
    "    # Create a table (DataFrame) object\n",
    "    worksheet.add_table(0, 0, num_rows, num_cols, {'columns': [{'header': col} for col in combined_df.columns], 'name': 'BulkBlockDealsTable'})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002541aa-ecce-4ffe-a230-fe70c9614520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd04bd-4769-43ba-b552-14cfbc565df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
