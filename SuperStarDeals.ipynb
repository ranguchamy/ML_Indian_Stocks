{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d62de36-a479-4563-9c6b-23ee95ca9f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet Name: Shareholding\n",
      "+----------------------------------------+------------+-------------------------------------------------------+----------------+-----------------+-------------------------+---------------+-----------+\n",
      "|                 Stock                  |    Code    |                      Client Name                      |    Holding     | Percent Holding | Stock Shareholding Page | Investor Type | File Date |\n",
      "+----------------------------------------+------------+-------------------------------------------------------+----------------+-----------------+-------------------------+---------------+-----------+\n",
      "|   Aarey Drugs & Pharmaceuticals Ltd.   | AAREYDRUGS |                Pi Opportunities Fund I                | Sold -0.09000  |      3.83       |           0.0           |      FII      | 20240206  |\n",
      "|             Bank of India              | BANKINDIA  |                      HDFC Group                       |  Above 1% now  |      1.15       |           0.0           | Institutional | 20240206  |\n",
      "|             Bank of India              | BANKINDIA  |     Hdfc Standard Life Insurance Company Limited      |  Above 1% now  |      1.15       |           0.0           | Institutional | 20240206  |\n",
      "|   Gandhar Oil Refinery (India) Ltd.    |  GANDHAR   |                      ICICI Group                      | Sold -0.17000  |      1.54       |           0.0           | Institutional | 20240206  |\n",
      "|            IRM Energy Ltd.             | IRMENERGY  |                      HDFC Group                       |  Above 1% now  |      1.46       |           0.0           | Institutional | 20240206  |\n",
      "|            IRM Energy Ltd.             | IRMENERGY  |     Hdfc Standard Life Insurance Company Limited      |  Above 1% now  |      1.46       |           0.0           | Institutional | 20240206  |\n",
      "|            IRM Energy Ltd.             | IRMENERGY  |                       SBI Group                       |  Above 1% now  |      1.47       |           0.0           | Institutional | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |            Abu Dhabi Investment Authority             |  Above 1% now  |      1.03       |           0.0           |      FII      | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |                      HDFC Group                       | Bought 0.12000 |      9.24       |           0.0           | Institutional | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |           Hdfc Mid - Capopportunities Fund            | Bought 0.05000 |      7.27       |           0.0           | Institutional | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |                   Hdfc Mutual Fund                    | Bought 0.05000 |      7.27       |           0.0           | Institutional | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |     Hdfc Standard Life Insurance Company Limited      | Bought 0.07000 |      1.97       |           0.0           | Institutional | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |                      ICICI Group                      | Sold -0.40000  |      2.74       |           0.0           | Institutional | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |                 Kotak Mahindra Group                  | Bought 0.07000 |       5.0       |           0.0           | Institutional | 20240206  |\n",
      "|         Ipca Laboratories Ltd.         |  IPCALAB   |          Mirae Asset Emerging Bluechip Fund           |  below 1% now  |       nan       |           0.0           | Institutional | 20240206  |\n",
      "|       NIIT Learning Systems Ltd.       |  NIITMTS   |         Massachusetts Institute Of Technology         |  below 1% now  |       nan       |           0.0           |      FII      | 20240206  |\n",
      "|        Nalin Lease Finance Ltd.        |   531212   |                Deepinder Singh Poonian                |  Above 1% now  |      1.18       |           0.0           |  Individual   | 20240206  |\n",
      "|      Prince Pipes & Fittings Ltd.      | PRINCEPIPE |            Government Pension Fund Global             | Bought 0.11000 |      2.37       |           0.0           |      FII      | 20240206  |\n",
      "|      Prince Pipes & Fittings Ltd.      | PRINCEPIPE |              India Capital Fund Limited               |  below 1% now  |       nan       |           0.0           |      FII      | 20240206  |\n",
      "|      Prince Pipes & Fittings Ltd.      | PRINCEPIPE |          Mirae Asset Emerging Bluechip Fund           |  below 1% now  |       nan       |           0.0           | Institutional | 20240206  |\n",
      "|           RPSG Ventures Ltd.           |  RPSGVENT  |             Clsa Global Markets Pte. Ltd.             |  below 1% now  |       nan       |           0.0           |      FII      | 20240206  |\n",
      "|         Stanpacks (India) Ltd.         |   530931   |                      Sangeetha S                      | Bought 0.41000 |      1.02       |           0.0           |  Individual   | 20240206  |\n",
      "|          State Bank of India           |    SBIN    |                      HDFC Group                       | Sold -0.01000  |      1.76       |           0.0           | Institutional | 20240206  |\n",
      "|          State Bank of India           |    SBIN    |                   Hdfc Mutual Fund                    | Sold -0.01000  |      1.76       |           0.0           | Institutional | 20240206  |\n",
      "|          State Bank of India           |    SBIN    |                      ICICI Group                      | Sold -0.09000  |      1.18       |           0.0           | Institutional | 20240206  |\n",
      "|          State Bank of India           |    SBIN    |             Icici Prudential Mutual Fund              | Sold -0.09000  |      1.18       |           0.0           | Institutional | 20240206  |\n",
      "|          State Bank of India           |    SBIN    |                       SBI Group                       | Sold -0.04000  |      2.98       |           0.0           | Institutional | 20240206  |\n",
      "|          State Bank of India           |    SBIN    |                    Sbi Mutual Fund                    | Sold -0.04000  |      2.98       |           0.0           | Institutional | 20240206  |\n",
      "|   The Investment Trust of India Ltd.   | THEINVEST  |                 Elm Park Fund Limited                 | Bought 4.13000 |      6.55       |           0.0           |      FII      | 20240206  |\n",
      "|   The Investment Trust of India Ltd.   | THEINVEST  |                  Hypnos Fund Limited                  |  below 1% now  |       nan       |           0.0           |      FII      | 20240206  |\n",
      "|       Unichem Laboratories Ltd.        | UNICHEMLAB |                      HDFC Group                       | Bought 0.24000 |      7.95       |           0.0           | Institutional | 20240206  |\n",
      "|       Unichem Laboratories Ltd.        | UNICHEMLAB |                  Hdfc Small Cap Fund                  | Bought 0.24000 |      7.95       |           0.0           | Institutional | 20240206  |\n",
      "|         Updater Services Ltd.          |    UDS     |                    Ashish Kacholia                    |  Above 1% now  |      1.96       |           0.0           |  Individual   | 20240206  |\n",
      "|         Updater Services Ltd.          |    UDS     |  Citigroup Global Markets Mauritius Private Limited   |  below 1% now  |       nan       |           0.0           |      FII      | 20240206  |\n",
      "|         Updater Services Ltd.          |    UDS     |                      ICICI Group                      | Bought 0.32000 |      3.18       |           0.0           | Institutional | 20240206  |\n",
      "|    Archean Chemical Industries Ltd.    |    ACI     |              Goldman Sachs India Limited              | Bought 0.59000 |      1.61       |           0.0           |      FII      | 20240205  |\n",
      "|    Archean Chemical Industries Ltd.    |    ACI     |                       SBI Group                       | Sold -0.04000  |       7.6       |           0.0           | Institutional | 20240205  |\n",
      "|          Huhtamaki India Ltd.          | HUHTAMAKI  |                     Seetha Kumari                     | Bought 0.30000 |      6.26       |           0.0           |  Individual   | 20240205  |\n",
      "|         TD Power Systems Ltd.          | TDPOWERSYS |              Goldman Sachs India Limited              | Bought 0.68000 |      2.33       |           0.0           |      FII      | 20240205  |\n",
      "|         TD Power Systems Ltd.          | TDPOWERSYS |                      HDFC Group                       | Bought 0.06000 |      3.71       |           0.0           | Institutional | 20240205  |\n",
      "|         TD Power Systems Ltd.          | TDPOWERSYS |                   Hdfc Mutual Fund                    | Bought 0.06000 |      3.71       |           0.0           | Institutional | 20240205  |\n",
      "|           Triveni Glass Ltd.           |   502281   |                 Mahendra Girdharilal                  | Bought 0.73000 |      4.14       |           0.0           |  Individual   | 20240205  |\n",
      "| Aptus Value Housing Finance India Ltd. |   APTUS    |                  Malabar Investments                  | Sold -1.02000  |      6.59       |           0.0           |      FII      | 20240203  |\n",
      "| Aptus Value Housing Finance India Ltd. |   APTUS    |                Smallcap World Fund Inc                | Bought 1.23000 |       3.7       |           0.0           |      FII      | 20240203  |\n",
      "| Aptus Value Housing Finance India Ltd. |   APTUS    |             Westbridge Crossover Fund Llc             | Bought 0.02000 |      34.46      |           0.0           | Institutional | 20240203  |\n",
      "|           Century Enka Ltd.            |  CENTENKA  |          Hitesh Ramji Javeri and Associates           | Bought 2.86000 |      5.38       |           0.0           |  Individual   | 20240203  |\n",
      "|         Exide Industries Ltd.          |  EXIDEIND  |                      ICICI Group                      |  below 1% now  |       nan       |           0.0           | Institutional | 20240203  |\n",
      "|         Exide Industries Ltd.          |  EXIDEIND  |         Icici Prudential Value Discovery Fund         |  below 1% now  |       nan       |           0.0           | Institutional | 20240203  |\n",
      "|         Exide Industries Ltd.          |  EXIDEIND  |                 Kotak Mahindra Group                  | Bought 0.52000 |      5.56       |           0.0           | Institutional | 20240203  |\n",
      "|          GeeCee Ventures Ltd.          |   GEECEE   |                    Akash Bhanshali                    |  Above 1% now  |      3.01       |           0.0           |  Individual   | 20240203  |\n",
      "|          GeeCee Ventures Ltd.          |   GEECEE   |                   Ashok Kumar Jain                    | Bought 0.43000 |      3.83       |           0.0           |  Individual   | 20240203  |\n",
      "|      Kaynes Technology India Ltd.      |   KAYNES   |                      HDFC Group                       |  Above 1% now  |      1.09       |           0.0           | Institutional | 20240203  |\n",
      "|      Kaynes Technology India Ltd.      |   KAYNES   |                   Hdfc Mutual Fund                    |  Above 1% now  |      1.09       |           0.0           | Institutional | 20240203  |\n",
      "|          Lancor Holdings Ltd.          |   509048   |                 Mahendra Girdharilal                  |  below 1% now  |       nan       |           0.0           |  Individual   | 20240203  |\n",
      "|        Manappuram Finance Ltd.         | MANAPPURAM | Stichting Depositary Apg Emerging Markets Equity Pool | Sold -0.15000  |      1.02       |           0.0           |      FII      | 20240203  |\n",
      "|                NCC Ltd.                |    NCC     |                      ICICI Group                      | Bought 1.20000 |      4.08       |           0.0           | Institutional | 20240203  |\n",
      "|                NCC Ltd.                |    NCC     |       Icici Prudential Balanced Advantage Fund        |  below 1% now  |       nan       |           0.0           | Institutional | 20240203  |\n",
      "|                NCC Ltd.                |    NCC     | Stichting Depositary Apg Emerging Markets Equity Pool | Bought 0.12000 |      1.12       |           0.0           |      FII      | 20240203  |\n",
      "|          Paisalo Digital Ltd.          |  PAISALO   |            Antara India Evergreen Fund Ltd            | Sold -1.78000  |       9.8       |           0.0           |      FII      | 20240203  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                     Abakkus Fund                      | Sold -0.64000  |      2.14       |           0.0           | Institutional | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                     Abakkus Fund                      | Sold -0.64000  |      2.14       |           0.0           | Institutional | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                      HDFC Group                       |  Above 1% now  |      2.44       |           0.0           | Institutional | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                      HDFC Group                       |  Above 1% now  |      2.44       |           0.0           | Institutional | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                   Hdfc Mutual Fund                    |  Above 1% now  |      2.44       |           0.0           | Institutional | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                   Hdfc Mutual Fund                    |  Above 1% now  |      2.44       |           0.0           | Institutional | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                     Mukul Agrawal                     | Sold -0.21000  |      1.02       |           0.0           |  Individual   | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                     Mukul Agrawal                     | Sold -0.21000  |      1.02       |           0.0           |  Individual   | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |             Mukul Mahavir Prasad Agrawal              | Sold -0.21000  |      1.02       |           0.0           |  Individual   | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |             Mukul Mahavir Prasad Agrawal              | Sold -0.21000  |      1.02       |           0.0           |  Individual   | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                    Sunil Singhania                    | Sold -0.64000  |      2.14       |           0.0           |  Individual   | 20240202  |\n",
      "|       Ion Exchange (India) Ltd.        | IONEXCHANG |                    Sunil Singhania                    | Sold -0.64000  |      2.14       |           0.0           |  Individual   | 20240202  |\n",
      "|          Evexia Lifecare Ltd.          |   524444   |                Lts Investment Fund Ltd                | Sold -1.93000  |      1.43       |           0.0           |      FII      | 20240201  |\n",
      "|  Hindustan Construction Company Ltd.   |    HCC     |                     Vanguard Fund                     | Bought 0.11000 |      2.19       |           0.0           |      FII      | 20240201  |\n",
      "|     Monarch Networth Capital Ltd.      |  MONARCH   |               Nomura Singapore Limited                |  below 1% now  |       nan       |           0.0           |      FII      | 20240201  |\n",
      "+----------------------------------------+------------+-------------------------------------------------------+----------------+-----------------+-------------------------+---------------+-----------+\n",
      "\n",
      "Sheet Name: Insider Trading and SAST\n",
      "+------------------------------------+--------+------------------------------+-----------------+----------+----------------------+------------+--------------------------+----------+-------------------------+-----------------+--------+-------------------+-----------+\n",
      "|               Stock                |  Code  |         Client Name          | Client Category |  Action  | Reported to Exchange |  Quantity  | Post Transaction Holding | Traded % |         Period          | Regulation Type |  Mode  | Last Traded Price | File Date |\n",
      "+------------------------------------+--------+------------------------------+-----------------+----------+----------------------+------------+--------------------------+----------+-------------------------+-----------------+--------+-------------------+-----------+\n",
      "|      Krsnaa Diagnostics Ltd.       | KRSNAA | ICICI Prudential Mutual Fund |      Other      | Disposal | 2024-02-02 00:00:00  |  627828.0  |        -971138.0         |   2.08   | 14 Dec 2022 01 Feb 2024 |      29(2)      | Market |      712.65       | 20240206  |\n",
      "|      Krsnaa Diagnostics Ltd.       | KRSNAA | ICICI Prudential Mutual Fund |      Other      | Disposal | 2024-02-02 00:00:00  |  627828.0  |        -971138.0         |   2.08   | 14 Dec 2022 01 Feb 2024 |      29(2)      | Market |      712.65       | 20240206  |\n",
      "| Zee Entertainment Enterprises Ltd. |  ZEEL  | ICICI Prudential Mutual Fund |      Other      | Disposal | 2024-01-31 00:00:00  | 20648930.0 |        48850475.0        |   2.15   | 20 Jan 2024 30 Jan 2024 |      29(2)      | Market |      170.55       | 20240201  |\n",
      "| Zee Entertainment Enterprises Ltd. |  ZEEL  | ICICI Prudential Mutual Fund |      Other      | Disposal | 2024-01-31 00:00:00  | 20648930.0 |        48850475.0        |   2.15   | 20 Jan 2024 30 Jan 2024 |      29(2)      | Market |      170.55       | 20240201  |\n",
      "+------------------------------------+--------+------------------------------+-----------------+----------+----------------------+------------+--------------------------+----------+-------------------------+-----------------+--------+-------------------+-----------+\n",
      "\n",
      "Sheet Name: Bulk Block Deals\n",
      "+--------------------------------------------+---------+------------------------------------------------+----------+-----------+----------+---------------------+---------------+------------+----------+-------------------+-----------+\n",
      "|                   Stock                    |  Code   |                  Client Name                   | Exchange | Deal Type |  Action  |        Date         | Average Price |  Quantity  | Traded % | Last Traded Price | File Date |\n",
      "+--------------------------------------------+---------+------------------------------------------------+----------+-----------+----------+---------------------+---------------+------------+----------+-------------------+-----------+\n",
      "|         Data Infrastructure Trust          | 543225  |               AXIS BANK LIMITED                |   BSE    |   Bulk    |   Sell   | 2024-02-06 00:00:00 |    153.95     | 60600000.0 |  2.3281  |      153.95       | 20240206  |\n",
      "|         Data Infrastructure Trust          | 543225  |               AXIS BANK LIMITED                |   BSE    |   Bulk    |   Sell   | 2024-02-06 00:00:00 |    153.95     | 60600000.0 |  2.3281  |      153.95       | 20240206  |\n",
      "| Krishna Institute of Medical Sciences Ltd. | 543308  |         SBI LIFE INSURANCE COMPANY LTD         |   BSE    |   Bulk    | Purchase | 2024-02-06 00:00:00 |    2085.0     | 1149074.0  |  1.4358  |      2133.6       | 20240206  |\n",
      "|              LKP Finance Ltd.              | 507912  |              DHEERAJ KUMAR LOHIA               |   BSE    |   Bulk    | Purchase | 2024-02-05 00:00:00 |    261.35     |  75000.0   |  0.5967  |      261.35       | 20240205  |\n",
      "|              LKP Finance Ltd.              | 507912  |              DHEERAJ KUMAR LOHIA               |   BSE    |   Bulk    | Purchase | 2024-02-05 00:00:00 |    261.35     |  75000.0   |  0.5967  |      261.35       | 20240205  |\n",
      "|              PB Fintech Ltd.               | 543390  |            PI OPPORTUNITIES FUND II            |   BSE    |   Bulk    |   Sell   | 2024-02-02 00:00:00 |    985.07     | 4643528.0  |  1.0291  |      981.25       | 20240202  |\n",
      "|              PB Fintech Ltd.               | 543390  |            PI OPPORTUNITIES FUND II            |   BSE    |   Bulk    |   Sell   | 2024-02-02 00:00:00 |    985.07     | 4643528.0  |  1.0291  |      981.25       | 20240202  |\n",
      "|            Larsen & Toubro Ltd.            | 500510  | JUPITER SOUTH ASIA INVESTMENT COMPANY LIMITED  |   BSE    |   Block   |   Sell   | 2024-02-01 00:00:00 |    3480.15    |  215505.0  |  0.0153  |      3398.0       | 20240201  |\n",
      "|           Olectra Greentech Ltd.           | 532439  | JUPITER SOUTH ASIA INVESTMENT COMPANY LIMITED  |   BSE    |   Block   |   Sell   | 2024-02-01 00:00:00 |    1741.1     |  184114.0  |  0.2243  |      1727.55      | 20240201  |\n",
      "|              PB Fintech Ltd.               | 543390  | AMERICAN FUNDS INSURANCE SERIES NEW WORLD FUND |   BSE    |   Block   | Purchase | 2024-02-01 00:00:00 |     992.8     |  881140.0  |  0.1953  |       997.8       | 20240201  |\n",
      "|              PB Fintech Ltd.               | 543390  | AMERICAN FUNDS INSURANCE SERIES NEW WORLD FUND |   BSE    |   Block   | Purchase | 2024-02-01 00:00:00 |     992.8     |  881140.0  |  0.1953  |       997.8       | 20240201  |\n",
      "|              PB Fintech Ltd.               | 543390  |               NEW WORLD FUND INC               |   BSE    |   Block   | Purchase | 2024-02-01 00:00:00 |     992.8     | 4705015.0  |  1.0428  |       997.8       | 20240201  |\n",
      "|              PB Fintech Ltd.               | 543390  |               NEW WORLD FUND INC               |   BSE    |   Block   | Purchase | 2024-02-01 00:00:00 |     992.8     | 7725000.0  |  1.7121  |       997.8       | 20240201  |\n",
      "|              PB Fintech Ltd.               | 543390  |               NEW WORLD FUND INC               |   BSE    |   Block   | Purchase | 2024-02-01 00:00:00 |     992.8     | 2096483.0  |  0.4646  |       997.8       | 20240201  |\n",
      "|              PB Fintech Ltd.               | 543390  |            SMALLCAP WORLD FUND INC             |   BSE    |   Block   | Purchase | 2024-02-01 00:00:00 |     992.8     | 6367319.0  |  1.4112  |       997.8       | 20240201  |\n",
      "|            Patanjali Foods Ltd.            | 500368  | JUPITER SOUTH ASIA INVESTMENT COMPANY LIMITED  |   BSE    |   Block   |   Sell   | 2024-02-01 00:00:00 |    1582.8     |  259551.0  |  0.0717  |      1570.35      | 20240201  |\n",
      "|      Salasar Techno Engineering Ltd.       | SALASAR |            NOMURA SINGAPORE LIMITED            |   NSE    |   Bulk    |   Sell   | 2024-02-01 00:00:00 |     28.2      | 3470000.0  |  1.0991  |       28.0        | 20240201  |\n",
      "+--------------------------------------------+---------+------------------------------------------------+----------+-----------+----------+---------------------+---------------+------------+----------+-------------------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
      "C:\\Users\\91908\\AppData\\Local\\Temp\\ipykernel_1236\\2235952782.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip01022024.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundSuperstars'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "\n",
    "# Read values to match from the Excel file (ActiveTrader from third sheet)\n",
    "values_df = pd.read_excel(values_excel_path, sheet_name='Superstars', header=None, skiprows=1)\n",
    "values_to_match = values_df.iloc[:, 0].astype(str).str.lower().tolist()\n",
    "\n",
    "# Dictionary to store results for each sheet name\n",
    "merged_results = {}\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None, header=6)  # Headers start from the seventh row\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Check if 'Client Name' column exists in the DataFrame\n",
    "            if 'Client Name' in df.columns:\n",
    "                # Convert the 'Client Name' column to lowercase and filter rows\n",
    "                filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
    "\n",
    "                # Check if the columns exist before attempting to drop them\n",
    "                columns_to_drop = ['Stock URL', 'ISIN', 'Stock Deals Page']\n",
    "                columns_to_drop = [col for col in columns_to_drop if col in filtered_rows.columns]\n",
    "                filtered_rows = filtered_rows.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "                # Reset the index before adding a new column\n",
    "                filtered_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Add a new column for file date\n",
    "                filtered_rows['File Date'] = file_date\n",
    "\n",
    "                # Check if the sheet name exists in the merged results dictionary\n",
    "                if sheet_name not in merged_results:\n",
    "                    merged_results[sheet_name] = filtered_rows\n",
    "                else:\n",
    "                    # Append the filtered rows to the existing sheet name\n",
    "                    merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "        # outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "        # os.rename(file_path, outbound_file_path)\n",
    "        # print(f\"File moved to: {outbound_file_path}\")\n",
    "\n",
    "# Display merged results\n",
    "for sheet_name, merged_df in merged_results.items():\n",
    "    # Display the sheet name\n",
    "    print(f\"\\nSheet Name: {sheet_name}\")\n",
    "\n",
    "    # Check if there are any rows in the merged result\n",
    "    if not merged_df.empty:\n",
    "        # Sort the result based on 'Code' and 'File Date'\n",
    "        #sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "        sorted_rows = merged_df.sort_values(by=['File Date', 'Stock','Client Name'], ascending=[False, True, True])\n",
    "\n",
    " \n",
    "        # Display the sorted rows in a tabular format\n",
    "        print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    else:\n",
    "        print(\"No data present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324cb81-eef6-4548-a4de-ebb7a03134b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automated super star Deal with file movement and without email client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a3fa4-c7a4-4ed9-b46d-e44d8486a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip090120240057.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundSuperstars'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "\n",
    "# Read values to match from the Excel file (ActiveTrader from third sheet)\n",
    "values_df = pd.read_excel(values_excel_path, sheet_name='Superstars', header=None, skiprows=1)\n",
    "values_to_match = values_df.iloc[:, 0].astype(str).str.lower().tolist()\n",
    "\n",
    "# Dictionary to store results for each sheet name\n",
    "merged_results = {}\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None, header=6)  # Headers start from the seventh row\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Check if 'Client Name' column exists in the DataFrame\n",
    "            if 'Client Name' in df.columns:\n",
    "                # Convert the 'Client Name' column to lowercase and filter rows\n",
    "                filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
    "\n",
    "                # Check if the columns exist before attempting to drop them\n",
    "                columns_to_drop = ['Stock URL', 'ISIN', 'Stock Deals Page']\n",
    "                columns_to_drop = [col for col in columns_to_drop if col in filtered_rows.columns]\n",
    "                filtered_rows = filtered_rows.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "                # Reset the index before adding a new column\n",
    "                filtered_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Add a new column for file date\n",
    "                filtered_rows['File Date'] = file_date\n",
    "\n",
    "                # Check if the sheet name exists in the merged results dictionary\n",
    "                if sheet_name not in merged_results:\n",
    "                    merged_results[sheet_name] = filtered_rows\n",
    "                else:\n",
    "                    # Append the filtered rows to the existing sheet name\n",
    "                    merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "        outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "        os.rename(file_path, outbound_file_path)\n",
    "        print(f\"File moved to: {outbound_file_path}\")\n",
    "\n",
    "# Display merged results\n",
    "for sheet_name, merged_df in merged_results.items():\n",
    "    # Display the sheet name\n",
    "    print(f\"\\nSheet Name: {sheet_name}\")\n",
    "\n",
    "    # Check if there are any rows in the merged result\n",
    "    if not merged_df.empty:\n",
    "        # Sort the result based on 'Code' and 'File Date'\n",
    "        #sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "        sorted_rows = merged_df.sort_values(by=['File Date', 'Code'], ascending=[False, True])\n",
    "\n",
    "\n",
    "        # Display the sorted rows in a tabular format\n",
    "        print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    else:\n",
    "        print(\"No data present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca323d5-74ef-48aa-83ab-66c480162587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip23012024.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundSuperstars'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "\n",
    "# Read values to match from the Excel file (ActiveTrader from third sheet)\n",
    "values_df = pd.read_excel(values_excel_path, sheet_name='Superstars', header=None, skiprows=1)\n",
    "values_to_match = values_df.iloc[:, 0].astype(str).str.lower().tolist()\n",
    "\n",
    "# Dictionary to store results for each sheet name\n",
    "merged_results = {}\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None, header=6)  # Headers start from the seventh row\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Check if 'Client Name' column exists in the DataFrame\n",
    "            if 'Client Name' in df.columns:\n",
    "                # Convert the 'Client Name' column to lowercase and filter rows\n",
    "                filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
    "\n",
    "                # Check if the columns exist before attempting to drop them\n",
    "                columns_to_drop = ['Stock URL', 'ISIN', 'Stock Deals Page']\n",
    "                columns_to_drop = [col for col in columns_to_drop if col in filtered_rows.columns]\n",
    "                filtered_rows = filtered_rows.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "                # Reset the index before adding a new column\n",
    "                filtered_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Add a new column for file date\n",
    "                filtered_rows['File Date'] = file_date\n",
    "\n",
    "                # Check if the sheet name exists in the merged results dictionary\n",
    "                if sheet_name not in merged_results:\n",
    "                    merged_results[sheet_name] = filtered_rows\n",
    "                else:\n",
    "                    # Append the filtered rows to the existing sheet name\n",
    "                    merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "        # outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "        # os.rename(file_path, outbound_file_path)\n",
    "        # print(f\"File moved to: {outbound_file_path}\")\n",
    "\n",
    "# Display merged results\n",
    "for sheet_name, merged_df in merged_results.items():\n",
    "    # Display the sheet name\n",
    "    print(f\"\\nSheet Name: {sheet_name}\")\n",
    "\n",
    "    # Check if there are any rows in the merged result\n",
    "    if not merged_df.empty:\n",
    "        # Sort the result based on 'Code' and 'File Date'\n",
    "        #sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "        sorted_rows = merged_df.sort_values(by=['File Date', 'Stock','Client Name'], ascending=[False, True, True])\n",
    "\n",
    " \n",
    "        # Display the sorted rows in a tabular format\n",
    "        print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    else:\n",
    "        print(\"No data present.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
