{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d3a3fa4-c7a4-4ed9-b46d-e44d8486a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "\n",
    "# Read values to match from the Excel file (ActiveTrader from third sheet)\n",
    "values_df = pd.read_excel(values_excel_path, sheet_name='Superstars', header=None, skiprows=1)\n",
    "values_to_match = values_df.iloc[:, 0].astype(str).str.lower().tolist()\n",
    "\n",
    "# Dictionary to store results for each sheet name\n",
    "merged_results = {}\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None, header=6)  # Headers start from the seventh row\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Check if 'Client Name' column exists in the DataFrame\n",
    "            if 'Client Name' in df.columns:\n",
    "                # Convert the 'Client Name' column to lowercase and filter rows\n",
    "                filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
    "\n",
    "                # Check if the columns exist before attempting to drop them\n",
    "                columns_to_drop = ['Stock URL', 'ISIN', 'Stock Deals Page']\n",
    "                columns_to_drop = [col for col in columns_to_drop if col in filtered_rows.columns]\n",
    "                filtered_rows = filtered_rows.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "                # Reset the index before adding a new column\n",
    "                filtered_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Add a new column for file date\n",
    "                filtered_rows['File Date'] = file_date\n",
    "\n",
    "                # Check if the sheet name exists in the merged results dictionary\n",
    "                if sheet_name not in merged_results:\n",
    "                    merged_results[sheet_name] = filtered_rows\n",
    "                else:\n",
    "                    # Append the filtered rows to the existing sheet name\n",
    "                    merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "        # outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "        # os.rename(file_path, outbound_file_path)\n",
    "        # print(f\"File moved to: {outbound_file_path}\")\n",
    "\n",
    "# Display merged results\n",
    "for sheet_name, merged_df in merged_results.items():\n",
    "    # Display the sheet name\n",
    "    print(f\"\\nSheet Name: {sheet_name}\")\n",
    "\n",
    "    # Check if there are any rows in the merged result\n",
    "    if not merged_df.empty:\n",
    "        # Sort the result based on 'Code' and 'File Date'\n",
    "        sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "\n",
    "        # Display the sorted rows in a tabular format\n",
    "        print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    else:\n",
    "        print(\"No data present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324cb81-eef6-4548-a4de-ebb7a03134b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automated super star Deal with file movement and without email client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a3fa4-c7a4-4ed9-b46d-e44d8486a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path to the Excel file with values to match\n",
    "values_excel_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\Scrip\\Scrip.xlsx'\n",
    "\n",
    "# Path to the folder with multiple Excel files\n",
    "inbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\InboundSuperstars'\n",
    "outbound_folder_path = r'C:\\Users\\91908\\Documents\\Raja\\Share market\\Analysis\\Trendlyne\\Data\\OutboundSuperstars'\n",
    "\n",
    "# Read values to match from the Excel file (ActiveTrader from third sheet)\n",
    "values_df = pd.read_excel(values_excel_path, sheet_name='Superstars', header=None, skiprows=1)\n",
    "values_to_match = values_df.iloc[:, 0].astype(str).str.lower().tolist()\n",
    "\n",
    "# Dictionary to store results for each sheet name\n",
    "merged_results = {}\n",
    "\n",
    "# Get a list of Excel files in the inbound folder\n",
    "inbound_files = [os.path.join(inbound_folder_path, file) for file in os.listdir(inbound_folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Check if there are no files in the inbound folder\n",
    "if not inbound_files:\n",
    "    print(\"No files present in the inbound folder.\")\n",
    "else:\n",
    "    # Iterate through each file\n",
    "    for file_path in inbound_files:\n",
    "        # Extract file date from the filename\n",
    "        file_date = os.path.basename(file_path)[:8]\n",
    "\n",
    "        # Read all sheets from the Excel file into a dictionary of DataFrames\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None, header=6)  # Headers start from the seventh row\n",
    "\n",
    "        # Iterate through each sheet\n",
    "        for sheet_name, df in dfs.items():\n",
    "            # Check if 'Client Name' column exists in the DataFrame\n",
    "            if 'Client Name' in df.columns:\n",
    "                # Convert the 'Client Name' column to lowercase and filter rows\n",
    "                filtered_rows = df[df['Client Name'].astype(str).str.lower().str.contains('|'.join(values_to_match), na=False)]\n",
    "\n",
    "                # Check if the columns exist before attempting to drop them\n",
    "                columns_to_drop = ['Stock URL', 'ISIN', 'Stock Deals Page']\n",
    "                columns_to_drop = [col for col in columns_to_drop if col in filtered_rows.columns]\n",
    "                filtered_rows = filtered_rows.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "                # Reset the index before adding a new column\n",
    "                filtered_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Add a new column for file date\n",
    "                filtered_rows['File Date'] = file_date\n",
    "\n",
    "                # Check if the sheet name exists in the merged results dictionary\n",
    "                if sheet_name not in merged_results:\n",
    "                    merged_results[sheet_name] = filtered_rows\n",
    "                else:\n",
    "                    # Append the filtered rows to the existing sheet name\n",
    "                    merged_results[sheet_name] = pd.concat([merged_results[sheet_name], filtered_rows])\n",
    "\n",
    "        # Move the file to the outbound folder after processing all sheets\n",
    "        outbound_file_path = os.path.join(outbound_folder_path, os.path.basename(file_path))\n",
    "        os.rename(file_path, outbound_file_path)\n",
    "        print(f\"File moved to: {outbound_file_path}\")\n",
    "\n",
    "# Display merged results\n",
    "for sheet_name, merged_df in merged_results.items():\n",
    "    # Display the sheet name\n",
    "    print(f\"\\nSheet Name: {sheet_name}\")\n",
    "\n",
    "    # Check if there are any rows in the merged result\n",
    "    if not merged_df.empty:\n",
    "        # Sort the result based on 'Code' and 'File Date'\n",
    "        sorted_rows = merged_df.sort_values(by=['Code', 'File Date'])\n",
    "\n",
    "        # Display the sorted rows in a tabular format\n",
    "        print(tabulate(sorted_rows, headers='keys', tablefmt='pretty', showindex=False))\n",
    "    else:\n",
    "        print(\"No data present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca323d5-74ef-48aa-83ab-66c480162587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
